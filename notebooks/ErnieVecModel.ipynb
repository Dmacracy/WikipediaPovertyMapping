{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
    "        super(DocModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        \n",
    "        self.docvecpipeline = nn.Sequential(\n",
    "            nn.Linear(self.input_size, self.hidden_size1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(self.hidden_size1, self.hidden_size2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, invecs, return_hidden=False):\n",
    "        hidden = self.docvecpipeline(invecs)\n",
    "        output = self.regressor(hidden)\n",
    "        if return_hidden:\n",
    "            return output, hidden\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocModelNet = DocModel(768, 512, 256)\n",
    "\n",
    "lr = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optim = optim.Adam(DocModelNet.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'rwanda'\n",
    "country_abrev = 'RWA'\n",
    "year = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_wiki = pd.read_csv(f'articles/{country}_Wiki.csv')\n",
    "dhs_clusts = dhs_clusts = pd.read_csv('data/dhs_clusters.csv')\n",
    "country_clusts = country_clusts = dhs_clusts[(dhs_clusts['country']== country) & (dhs_clusts['year']== year)]\n",
    "# Convert string to np array because it was stored stupidly. Will fix later\n",
    "country_wiki['embedding'] = country_wiki['embedding'].apply(lambda x: np.fromstring(x[1:-1], \n",
    "                                                                                    sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(c1, c2):\n",
    "    '''\n",
    "    Compute approx distance between two coords given in (lat, long)\n",
    "    format. \n",
    "    '''\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    lat1 = np.radians(c1[0])\n",
    "    lon1 = np.radians(c1[1])\n",
    "    lat2 = np.radians(c2[0])\n",
    "    lon2 = np.radians(c2[1])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def test_compute_dist():\n",
    "    '''\n",
    "    Unit test for compute_distance function.\n",
    "    \n",
    "    Uses Berkeley School of Infromation and Moscone Center South in San Fransisco\n",
    "    as a test case. Distance from Google maps. \n",
    "    '''\n",
    "    moscone_south = (37.783957939867015, -122.40107973374062) # lat, long\n",
    "    i_school = (37.871363468005065, -122.25852213941603) \n",
    "    correct_dist = 15.6 # in km\n",
    "    computed_dist = compute_distance(moscone_south, i_school)\n",
    "    np.testing.assert_approx_equal(computed_dist, correct_dist, significant=2)\n",
    "\n",
    "def get_dists_to_articles(country_clust, country_wiki):\n",
    "    dists = []\n",
    "    for i in range(len(country_wiki)):\n",
    "        dist = compute_distance((country_clust['lat'], country_clust['lon']),\n",
    "                                (country_wiki['latitude'], country_wiki['longitude']))\n",
    "        dists.append()\n",
    "    \n",
    "    \n",
    "def get_closest_n(cluster, article_df):\n",
    "    for \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'latitude', 'longitude', 'text', 'embedding'], dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_wiki.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_compute_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0725], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc_model(torch.tensor(country_wiki['embedding'].iloc[0]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        cond = torch.Tensor(infos[i]).to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu, cond.reshape((batch_size, ninfo))).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate batch of random conditional vectors\n",
    "        idx = probs.multinomial(1)\n",
    "        rand_cond = infos[idx]\n",
    "        rand_cond = rand_cond.reshape(rand_cond.shape[1:]).to(device)\n",
    "        #rand_title = titles[idx]\n",
    "        #rand_title = rand_title.reshape(rand_title.shape[1:]).to(device)\n",
    "        \n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise, rand_cond.reshape((batch_size, ninfo))) #, \n",
    "                   #rand_title.reshape((batch_size, ntitlevect)))\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach(), rand_cond.reshape((batch_size, ninfo))).view(-1)\n",
    "        #  rand_title.reshape((batch_size, ntitlevect))\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        \n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake, rand_cond.reshape((batch_size, ninfo))).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 50 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise, fixed_cond.reshape((batch_size, ninfo))).detach().cpu() #,\n",
    "                           #fixed_titles.reshape((batch_size, ntitlevect))).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
