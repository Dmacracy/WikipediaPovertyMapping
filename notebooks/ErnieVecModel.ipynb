{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmac/.local/lib/python3.8/site-packages/tqdm/std.py:670: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes):\n",
    "        super(DocModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        \n",
    "        modlist = []\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                modlist.append(nn.Sequential(\n",
    "                    nn.Linear(self.input_size, self.hidden_sizes[i]),\n",
    "                    nn.LeakyReLU()))\n",
    "            else:\n",
    "                modlist.append(nn.Sequential(\n",
    "                    nn.Linear(self.hidden_sizes[i-1], self.hidden_sizes[i]),\n",
    "                    nn.LeakyReLU()))\n",
    "                               \n",
    "        self.docvecpipeline = nn.ModuleList(modlist)\n",
    "        \n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(self.hidden_sizes[-1], 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, invecs):\n",
    "        hidden = invecs\n",
    "        for i, layer in enumerate(self.docvecpipeline):\n",
    "            hidden = layer(hidden)\n",
    "        output = self.regressor(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data to Use and Data Prep Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'rwanda'\n",
    "country_abrev = 'RWA'\n",
    "year = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_wiki = pd.read_csv(f'articles/{country}_Wiki.csv')\n",
    "dhs_clusts = dhs_clusts = pd.read_csv('data/dhs_clusters.csv')\n",
    "country_clusts = country_clusts = dhs_clusts[(dhs_clusts['country']== country) & (dhs_clusts['year']== year)]\n",
    "# Convert string to np array because it was stored stupidly. Will fix later\n",
    "country_wiki['embedding'] = country_wiki['embedding'].apply(lambda x: np.fromstring(x[1:-1], \n",
    "                                                                                    sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(c1, c2):\n",
    "    '''\n",
    "    Compute approx distance between two coords given in (lat, long)\n",
    "    format. \n",
    "    '''\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    lat1 = np.radians(c1[0])\n",
    "    lon1 = np.radians(c1[1])\n",
    "    lat2 = np.radians(c2[0])\n",
    "    lon2 = np.radians(c2[1])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def test_compute_dist():\n",
    "    '''\n",
    "    Unit test for compute_distance function.\n",
    "    \n",
    "    Uses Berkeley School of Information and Moscone Center South in San Fransisco\n",
    "    as a test case. Distance from Google maps. \n",
    "    '''\n",
    "    moscone_south = (37.783957939867015, -122.40107973374062) # lat, long\n",
    "    i_school = (37.871363468005065, -122.25852213941603) \n",
    "    correct_dist = 15.6 # in km\n",
    "    computed_dist = compute_distance(moscone_south, i_school)\n",
    "    np.testing.assert_approx_equal(computed_dist, correct_dist, significant=2)\n",
    "\n",
    "def get_dists_to_articles(country_clust, country_wiki):\n",
    "    '''\n",
    "    For a given DHS cluster, get the distance to each of the wiki \n",
    "    articles and return it as a numpy array.\n",
    "    '''\n",
    "    dists = []\n",
    "    for i in range(len(country_wiki)):\n",
    "        dist = compute_distance((country_clust['lat'], country_clust['lon']),\n",
    "                                (country_wiki['latitude'].iloc[i], country_wiki['longitude'].iloc[i]))\n",
    "        dists.append(dist)\n",
    "    return np.array(dists)\n",
    "\n",
    "def get_closest_n(dists_to_articles, n=10):\n",
    "    '''\n",
    "    Get the n closest articles to a given cluster.\n",
    "    Returns the indices ofthe articles and the approx distances in km.\n",
    "    '''\n",
    "    top_inds = np.argsort(dists_to_articles)[:n]\n",
    "    #np.argpartition(dists_to_articles, n)[:n]\n",
    "    return top_inds, dists_to_articles[top_inds]\n",
    "\n",
    "def get_input_tensor(country_clust,  country_wiki):\n",
    "    '''\n",
    "    For a given DHS cluster, get the input tensor that \n",
    "    we will feed to the model.\n",
    "    '''\n",
    "    embedds = []\n",
    "    for i, closest_idx in enumerate(country_clust['closest_article_idxs']):\n",
    "        embedds.append(country_wiki['embedding'].iloc[closest_idx])\n",
    "    dists = torch.tensor(country_clust['closest_article_dists']).float()\n",
    "    embedds = torch.flatten(torch.tensor(np.array(embedds))).float()\n",
    "    return embedds, dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [00:03<00:00, 147.21it/s]\n",
      "<ipython-input-6-145585cbc2fb>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_clusts['dists_to_articles'] = \\\n"
     ]
    }
   ],
   "source": [
    "country_clusts['dists_to_articles'] = \\\n",
    "country_clusts.progress_apply(lambda x : get_dists_to_articles(x, country_wiki), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [00:00<00:00, 9121.76it/s]\n"
     ]
    }
   ],
   "source": [
    "country_clusts[['closest_article_idxs', 'closest_article_dists']] = \\\n",
    "country_clusts.progress_apply(lambda x: get_closest_n(np.array(x['dists_to_articles'])), \n",
    "                              axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [00:00<00:00, 1875.67it/s]\n"
     ]
    }
   ],
   "source": [
    "country_clusts[['input_embedds', 'input_dists']] = \\\n",
    "country_clusts.progress_apply(lambda clust: get_input_tensor(clust, country_wiki), \n",
    "                     axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocModel(\n",
       "  (docvecpipeline): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=7680, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = 768\n",
    "num_close_arts = 10\n",
    "\n",
    "#DocModelNet = DocModel(10, [5, 2])\n",
    "\n",
    "DocModelNet = DocModel(embed_size * num_close_arts, [512, 512, 256, 32])\n",
    "\n",
    "lr = 0.0001\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(DocModelNet.parameters(), lr=lr)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DocModelNet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "epoch 0    avg loss 0.2547353473017306\n",
      "\n",
      "epoch 1    avg loss 0.20810543663274036\n",
      "\n",
      "epoch 2    avg loss 0.17284417288137788\n",
      "\n",
      "epoch 3    avg loss 0.14929311266750217\n",
      "\n",
      "epoch 4    avg loss 0.13553155002154804\n",
      "\n",
      "epoch 5    avg loss 0.15152846720673865\n",
      "\n",
      "epoch 6    avg loss 0.09661955052957016\n",
      "\n",
      "epoch 7    avg loss 0.09213685304240332\n",
      "\n",
      "epoch 8    avg loss 0.07858333206451555\n",
      "\n",
      "epoch 9    avg loss 0.07665008246217685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# avg loss per epoch\n",
    "epoch_losses = []\n",
    "\n",
    "# Training Loop\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # list of individ cluster losses for this epoch\n",
    "    iter_losses = []\n",
    "    # for each training point\n",
    "    for i in range(len(country_clusts)):\n",
    "        # clear gradient fro prev instance\n",
    "        DocModelNet.zero_grad()\n",
    "        # Get inputs\n",
    "        #embedd = country_clusts['input_dists'].iloc[i].to(device)\n",
    "        embedd = country_clusts['input_embedds'].iloc[i].to(device)\n",
    "        # get target wealth value \n",
    "        target = torch.tensor(country_clusts['wealthpooled'].iloc[i]).float().to(device)\n",
    "        # get model output\n",
    "        output = DocModelNet(embedd)\n",
    "        # Calculate loss based on this output and the loss funct\n",
    "        err = criterion(output[0], target)\n",
    "        # Calculate gradients\n",
    "        err.backward()\n",
    "        # Update network params using the optimizer\n",
    "        optimizer.step()\n",
    "        # Save Loss for plotting and analysis\n",
    "        iter_losses.append(err.item())\n",
    "\n",
    "    epoch_losses.append(np.mean(iter_losses))\n",
    "    print(f\"epoch {epoch}    avg loss {epoch_losses[epoch]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_wealth(clust, model, country_wiki):\n",
    "    #embedd = clust['input_dists'].to(device)\n",
    "    embedd = clust['input_embedds'].to(device)\n",
    "    \n",
    "    #print(embedd)\n",
    "    output = model(embedd)\n",
    "    return output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-bb71e14a62fd>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_clusts['pred_wealth'] = \\\n"
     ]
    }
   ],
   "source": [
    "country_clusts['pred_wealth'] = \\\n",
    "country_clusts.apply(lambda clust : get_pred_wealth(clust, DocModelNet, country_wiki), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    492.000000\n",
       "mean      -0.465055\n",
       "std        0.344402\n",
       "min       -0.767587\n",
       "25%       -0.630059\n",
       "50%       -0.578560\n",
       "75%       -0.497021\n",
       "max        0.753728\n",
       "Name: pred_wealth, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_clusts['pred_wealth'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    492.000000\n",
       "mean      -0.481522\n",
       "std        0.497298\n",
       "min       -1.041967\n",
       "25%       -0.765138\n",
       "50%       -0.647184\n",
       "75%       -0.463005\n",
       "max        1.894964\n",
       "Name: wealthpooled, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_clusts['wealthpooled'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
