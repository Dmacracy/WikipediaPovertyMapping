{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmac/.local/lib/python3.8/site-packages/tqdm/std.py:670: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
    "        super(DocModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        \n",
    "        self.docvecpipeline = nn.Sequential(\n",
    "            nn.Linear(self.input_size, self.hidden_size1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(self.hidden_size1, self.hidden_size2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, invecs, return_hidden=False):\n",
    "        hidden = self.docvecpipeline(invecs)\n",
    "        output = self.regressor(hidden)\n",
    "        if return_hidden:\n",
    "            return output, hidden\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data to Use and Data Prep Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'rwanda'\n",
    "country_abrev = 'RWA'\n",
    "year = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_wiki = pd.read_csv(f'articles/{country}_Wiki.csv')\n",
    "dhs_clusts = dhs_clusts = pd.read_csv('data/dhs_clusters.csv')\n",
    "country_clusts = country_clusts = dhs_clusts[(dhs_clusts['country']== country) & (dhs_clusts['year']== year)]\n",
    "# Convert string to np array because it was stored stupidly. Will fix later\n",
    "country_wiki['embedding'] = country_wiki['embedding'].apply(lambda x: np.fromstring(x[1:-1], \n",
    "                                                                                    sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(c1, c2):\n",
    "    '''\n",
    "    Compute approx distance between two coords given in (lat, long)\n",
    "    format. \n",
    "    '''\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    lat1 = np.radians(c1[0])\n",
    "    lon1 = np.radians(c1[1])\n",
    "    lat2 = np.radians(c2[0])\n",
    "    lon2 = np.radians(c2[1])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def test_compute_dist():\n",
    "    '''\n",
    "    Unit test for compute_distance function.\n",
    "    \n",
    "    Uses Berkeley School of Infromation and Moscone Center South in San Fransisco\n",
    "    as a test case. Distance from Google maps. \n",
    "    '''\n",
    "    moscone_south = (37.783957939867015, -122.40107973374062) # lat, long\n",
    "    i_school = (37.871363468005065, -122.25852213941603) \n",
    "    correct_dist = 15.6 # in km\n",
    "    computed_dist = compute_distance(moscone_south, i_school)\n",
    "    np.testing.assert_approx_equal(computed_dist, correct_dist, significant=2)\n",
    "\n",
    "def get_dists_to_articles(country_clust, country_wiki):\n",
    "    '''\n",
    "    For a given DHS cluster, get the distance to each of the wiki \n",
    "    articles and return it as a numpy array.\n",
    "    '''\n",
    "    dists = []\n",
    "    for i in range(len(country_wiki)):\n",
    "        dist = compute_distance((country_clust['lat'], country_clust['lon']),\n",
    "                                (country_wiki['latitude'].iloc[i], country_wiki['longitude'].iloc[i]))\n",
    "        dists.append(dist)\n",
    "    return np.array(dists)\n",
    "\n",
    "def get_closest_n(dists_to_articles, n=10):\n",
    "    '''\n",
    "    Get the n closest articles to a given cluster.\n",
    "    Returns the indices ofthe articles and the approx distances in km.\n",
    "    '''\n",
    "    top_inds = np.argpartition(dists_to_articles, n)[:n]\n",
    "    return top_inds, dists_to_articles[top_inds]\n",
    "\n",
    "def get_input_tensor(country_clust,  country_wiki):\n",
    "    '''\n",
    "    For a given DHS cluster, get the input tensor that \n",
    "    we will feed to the model.\n",
    "    '''\n",
    "    embedds = []\n",
    "    for i, closest_idx in enumerate(country_clust['closest_article_idxs']):\n",
    "        embedds.append(country_wiki['embedding'].iloc[closest_idx])\n",
    "    dists = torch.tensor(country_clust['closest_article_dists']).float()\n",
    "    embedds = torch.flatten(torch.tensor(np.array(embedds))).float()\n",
    "    return embedds, dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [00:03<00:00, 157.68it/s]\n",
      "<ipython-input-95-d97e46bf5222>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_clusts['dists_to_articles'] = country_clusts.progress_apply(lambda x : get_dists_to_articles(x, country_wiki), axis=1)\n"
     ]
    }
   ],
   "source": [
    "country_clusts['dists_to_articles'] = \\\n",
    "country_clusts.progress_apply(lambda x : get_dists_to_articles(x, country_wiki), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [00:00<00:00, 15842.26it/s]\n",
      "/home/dmac/.local/lib/python3.8/site-packages/pandas/core/frame.py:3065: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "country_clusts[['closest_article_idxs', 'closest_article_dists']] = \\\n",
    "country_clusts.progress_apply(lambda x: get_closest_n(np.array(x['dists_to_articles'])), \n",
    "                              axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedds, dists = get_input_tensor(country_clusts.iloc[0], country_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 768\n",
    "num_close_arts = 10\n",
    "\n",
    "\n",
    "DocModelNet = DocModel(embed_size * num_close_arts, 512, 256)\n",
    "\n",
    "lr = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(DocModelNet.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "epoch=0\tepoch_losses[epoch]=3.3236665603452695\n",
      "epoch=1\tepoch_losses[epoch]=1.7000747878438802\n",
      "epoch=2\tepoch_losses[epoch]=0.6187574475565366\n",
      "epoch=3\tepoch_losses[epoch]=0.4425276971557496\n",
      "epoch=4\tepoch_losses[epoch]=0.48080637091821493\n",
      "epoch=5\tepoch_losses[epoch]=0.5059960214872095\n",
      "epoch=6\tepoch_losses[epoch]=0.2931360388643613\n",
      "epoch=7\tepoch_losses[epoch]=0.531150337622665\n",
      "epoch=8\tepoch_losses[epoch]=0.34341576027721343\n",
      "epoch=9\tepoch_losses[epoch]=0.3819233818119504\n"
     ]
    }
   ],
   "source": [
    "# avg loss per epoch\n",
    "epoch_losses = []\n",
    "\n",
    "# Training Loop\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # list of individ cluster losses for this epoch\n",
    "    iter_losses = []\n",
    "    # for each training point\n",
    "    for i in range(len(country_clusts)):\n",
    "        # clear gradient fro prev instance\n",
    "        test_doc_model.zero_grad()\n",
    "        # Get inputs\n",
    "        embedd, dists = get_input_tensor(country_clusts.iloc[i], country_wiki)\n",
    "        # get target wealth value \n",
    "        target = torch.tensor(country_clusts['wealthpooled'].iloc[i]).float()\n",
    "        # get model output\n",
    "        output = DocModelNet(embedd)\n",
    "        # Calculate loss based on this output and the loss funct\n",
    "        err = criterion(output, target)\n",
    "        # Calculate gradients\n",
    "        err.backward()\n",
    "        # Update network params using the optimizer\n",
    "        optimizer.step()\n",
    "        # Save Loss for plotting and analysis\n",
    "        iter_losses.append(err.item())\n",
    "\n",
    "    epoch_losses.append(np.mean(iter_losses))\n",
    "    print(f\"{epoch=}\\t{epoch_losses[epoch]=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
