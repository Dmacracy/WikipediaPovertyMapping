{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Nightlights(processed by DenseNet121) + Doc2Vec\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.misc import imshow, imresize\n",
    "import os\n",
    "import pickle\n",
    "import pdb\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D, Input, Concatenate,concatenate\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path: /atlas/u/chenlin/wikipedia_images/Poverty_prediction/Processed_data/2015-17_ghana/\n",
      "Test path: /atlas/u/chenlin/wikipedia_images/Poverty_prediction/Processed_data/2009-11_nigeria/\n"
     ]
    }
   ],
   "source": [
    "result_dir = '/atlas/u/esheehan/GUF_dataset/output/'\n",
    "tfrecord_dir = '/atlas/u/chenlin/wikipedia_images/Poverty_prediction/Processed_data/'\n",
    "\n",
    "files = ['2015-17_ghana', '2009-11_nigeria']\n",
    "tfrecord_train = tfrecord_dir + files[0]+'/'\n",
    "tfrecord_test = tfrecord_dir + files[1]+'/'\n",
    "\n",
    "print(\"Train path:\", tfrecord_train)\n",
    "print(\"Test path:\", tfrecord_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_doc2vec(i, num):\n",
    "    embeddings = []\n",
    "    for index, article in enumerate(i[6]):\n",
    "        #pdb.set_trace()\n",
    "        embeddings += list(article[4]) + [article[0]]\n",
    "        if index == num - 1:\n",
    "            break\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "band_names = ['BLUE', 'GREEN', 'RED']\n",
    "# x label\n",
    "\n",
    "## Not used in new version\n",
    "def _parse_function(example_proto):\n",
    "    features = {\n",
    "        band_name : tf.FixedLenFeature(shape=[255**2], dtype=tf.float32) for band_name in ['LAT','LON','RED','GREEN','BLUE','NIGHTLIGHTS']\n",
    "    }\n",
    "    features['wealthpooled'] = tf.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    for band_name in band_names:\n",
    "        parsed_features[band_name] = tf.cast(parsed_features[band_name], tf.float64)\n",
    "    parsed_features['wealthpooled'] = tf.cast(parsed_features['wealthpooled'], tf.float64)\n",
    "    parsed_features['LAT'] = tf.cast(parsed_features['LAT'], tf.float64)\n",
    "    parsed_features['LON'] = tf.cast(parsed_features['LON'], tf.float64)\n",
    "    return parsed_features \n",
    "\n",
    "\n",
    "\n",
    "def load_data(train_dir, test_dir):\n",
    "    tfrecord_train = []\n",
    "    tfrecord_test = []\n",
    "    options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "     \n",
    "    #load data\n",
    "    for name_index in range(len(glob.glob(train_dir+'*.gz'))):\n",
    "        tfrecord_train.append(train_dir+str(name_index)+'.tfrecord.gz')\n",
    "    for name_index in range(len(glob.glob(test_dir+'*.gz'))):\n",
    "        tfrecord_test.append(test_dir+str(name_index)+'.tfrecord.gz')\n",
    "\n",
    "    \n",
    "    X_train,Y_train, X_test, Y_test = [], [], [], []\n",
    "    with open(train_dir +'doc2vec_info.txt','rb') as f:\n",
    "        train_doc2vec = pickle.load(f)\n",
    "        \n",
    "    with open(test_dir +'doc2vec_info.txt','rb') as f:\n",
    "        test_doc2vec = pickle.load(f)\n",
    "    \n",
    "    for train_current in range(len(tfrecord_train)):\n",
    "        # file name, embeddings\n",
    "        if train_doc2vec[train_current][0] == None: # LAT,LON=NONE in tfrecord\n",
    "            continue\n",
    "        \n",
    "        X_train.append([tfrecord_train[train_current],np.array(concatenate_doc2vec(train_doc2vec[train_current][0],10))])\n",
    "        iterator = tf.python_io.tf_record_iterator(tfrecord_train[train_current], options=options)\n",
    "        record_str = next(iterator)\n",
    "        ex = tf.train.Example.FromString(record_str) \n",
    "        feature_map = ex.features.feature \n",
    "        Y_train.append(feature_map['wealthpooled'].float_list.value[0])\n",
    "        \n",
    "    for test_current in range(len(tfrecord_test)):\n",
    "        # file name, embeddings\n",
    "        if test_doc2vec[test_current][0] == None: # LAT, LON=NONE in tfrecord\n",
    "            continue\n",
    "        \n",
    "        X_test.append([tfrecord_test[test_current], np.array(concatenate_doc2vec(test_doc2vec[test_current][0],10))])\n",
    "        iterator = tf.python_io.tf_record_iterator(tfrecord_test[test_current], options=options)\n",
    "       \n",
    "        record_str = next(iterator)\n",
    "        ex = tf.train.Example.FromString(record_str) \n",
    "        \n",
    "        feature_map = ex.features.feature \n",
    "        Y_test.append(feature_map['wealthpooled'].float_list.value[0])\n",
    "        \n",
    "    print(\"Data Loaded\") \n",
    "    return X_train, Y_train,X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, Y_train,X_test, Y_test = load_data(tfrecord_train, tfrecord_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_embeding(doc2vecs, lat,lon):\n",
    "    closest = float('inf')\n",
    "    vec = None\n",
    "    for i in range(len(doc2vecs)):\n",
    "        if len(doc2vecs[i])>=5:\n",
    "            temp = (lat-doc2vecs[i][0][0])**2 + (lon-doc2vecs[i][0][1])**2\n",
    "            if temp<=closest:\n",
    "                closest = temp\n",
    "                vec = doc2vecs[i]\n",
    "    if vec:\n",
    "        return vec\n",
    "    return None\n",
    "\n",
    "\n",
    "# Images are 224x224 numpy arrays \n",
    "def load_model():\n",
    "    np.random.seed(1234)\n",
    "    model1 = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    densenet = DenseNet121(weights='imagenet')\n",
    "    densenet.layers.pop()\n",
    "    x = densenet(model1)\n",
    "    x = Dense(512, kernel_initializer='normal', activation='tanh')(x)\n",
    "    x = Dense(256)(x)\n",
    "    \n",
    "    model2 = Input(shape=(3010,))\n",
    "    #\n",
    "    x2 = Dense(512, kernel_initializer='normal', activation='sigmoid')(model2)\n",
    "    x2 = Dense(256, kernel_initializer='normal', activation='tanh')(x2)\n",
    "    merge = concatenate([x, x2])\n",
    "    #\n",
    "    \n",
    "    merge = Dense(512, input_shape=(2,256), kernel_initializer='normal', activation='relu')(merge)\n",
    "    merge = Dense(256, kernel_initializer='normal', activation='sigmoid')(merge)\n",
    "    #merge = Dense(256, kernel_initializer='normal', activation='relu')(merge)\n",
    "    merge = Dense(32, kernel_initializer='normal', activation='tanh')(merge)\n",
    "    #merge = Dense(32, kernel_initializer='normal', activation='relu')(merge)\n",
    "    merge = Dense(1, kernel_initializer='normal', kernel_regularizer=regularizers.l2(1e-7))(merge)\n",
    "    model = Model(inputs= [model1,model2], outputs=merge)\n",
    "    adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)#, metrics=[coeff_determination, 'mae'])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(tfrecord_train, tfrecord_test):\n",
    "    EPOCH = 15\n",
    "    BATCH_SIZE = 32\n",
    "    options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "    X_train, Y_train,X_test, Y_test = load_data(tfrecord_train, tfrecord_test) \n",
    "    \n",
    "    comb_train = list(zip(X_train, Y_train))\n",
    "    random.shuffle(comb_train)\n",
    "    X_train,Y_train = zip(*comb_train)\n",
    "    comb_test = list(zip(X_test, Y_test))\n",
    "    random.shuffle(comb_test)\n",
    "    X_test,Y_test = zip(*comb_test)\n",
    "    \n",
    "    #X_test = list(X_test)\n",
    "    #random.shuffle(X_test)\n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = list(X_train),list(Y_train), list(X_test), list(Y_test)\n",
    "    \n",
    "    model = load_model()\n",
    "    history = collections.defaultdict(float)\n",
    "    for epoch in range(EPOCH):\n",
    "        print(\"Starting epoch: {}\".format(epoch))\n",
    "        # iterate through all the training examples\n",
    "\n",
    "        for train_iterator in range(int(len(X_train)/BATCH_SIZE)):\n",
    "            images = np.zeros((BATCH_SIZE,224,224,3))\n",
    "            embeddings = np.zeros((BATCH_SIZE, 3010))\n",
    "            for item in range(BATCH_SIZE):\n",
    "                \n",
    "                embeddings[item] = X_train[train_iterator*BATCH_SIZE+item][1]\n",
    "                iterator = tf.python_io.tf_record_iterator(X_train[train_iterator*BATCH_SIZE+item][0], options=options)\n",
    "                record_str = next(iterator)\n",
    "                ex = tf.train.Example.FromString(record_str)  # parse into an actual Example message\n",
    "                feature_map = ex.features.feature  # get the mapping from feature name strings to Feature\n",
    "\n",
    "                n = feature_map['NIGHTLIGHTS'].float_list.value\n",
    "                n = np.array(n).reshape(224,-1)\n",
    "                images[item] = np.stack([n,n,n], axis=-1) \n",
    "                plt.imshow(images[item])\n",
    "            \n",
    "                #pdb.set_trace() \n",
    "            Index = Y_train[train_iterator*BATCH_SIZE: (train_iterator+1)*BATCH_SIZE]  \n",
    "            model_loss = model.train_on_batch([images,embeddings], Index)\n",
    "            prediction = model.predict([images,embeddings], batch_size=BATCH_SIZE)\n",
    "            trainMSE = mean_squared_error(np.asarray(Index),np.asarray(prediction))\n",
    "            trainR2 = r2_score(np.asarray(Index), np.asarray(prediction))         \n",
    "            history[(epoch, 'loss')] += model_loss\n",
    "                        \n",
    "        history[(epoch, 'loss')] /= int(len(X_train)/BATCH_SIZE)\n",
    "       \n",
    "        #print(history[(epoch, 'loss')])\n",
    "        print(\"Epoch \", epoch)\n",
    "        print(\"Train Loss\", history[(epoch, 'loss')])\n",
    "        \n",
    "           \n",
    "        ### VALIDATION \n",
    "        print(\"Testing function\")\n",
    "        all_labels = []\n",
    "        all_preds = [] \n",
    "        for test_iterator in range(int(len(X_test)/BATCH_SIZE)):\n",
    "            images_val = np.zeros((BATCH_SIZE,224,224,3))\n",
    "            embeddings_val = np.zeros((BATCH_SIZE, 3010))\n",
    "            for item in range(BATCH_SIZE):\n",
    "                embeddings_val[item] = X_test[test_iterator*BATCH_SIZE+item][1]\n",
    "                iterator = tf.python_io.tf_record_iterator(X_test[test_iterator*BATCH_SIZE+item][0], options=options)\n",
    "                record_str = next(iterator)\n",
    "                ex = tf.train.Example.FromString(record_str)  # parse into an actual Example message\n",
    "                feature_map = ex.features.feature  # get the mapping from feature name strings to Feature\n",
    "\n",
    "                n = feature_map['NIGHTLIGHTS'].float_list.value\n",
    "                n = np.array(n).reshape(224,-1)\n",
    "                images_val[item] = np.stack([n,n,n], axis=-1) \n",
    "            \n",
    "            Index_val = Y_test[test_iterator*BATCH_SIZE: (test_iterator+1)*BATCH_SIZE]                  \n",
    "            prediction_val = model.predict([images_val,embeddings_val], batch_size=BATCH_SIZE)\n",
    "            all_labels.append(Index_val)\n",
    "            all_preds.append(np.asarray(prediction_val))\n",
    "           \n",
    "        valR2 =  r2_score(np.concatenate(all_labels, axis=0).reshape(-1), np.concatenate(all_preds, axis=0).reshape(-1))\n",
    "        (rho,p_value) = stats.spearmanr(np.concatenate(all_labels, axis=0).reshape(-1), np.concatenate(all_preds, axis=0).reshape(-1))\n",
    "        length = len(np.concatenate(all_labels, axis=0))\n",
    "        (r_pearson,p_value_pearson) = stats.pearsonr(np.concatenate(all_labels, axis=0).reshape(-1), np.concatenate(all_preds, axis=0).reshape(-1))\n",
    "        valL2Loss = (1/length)*np.sum(np.square(np.concatenate(all_labels, axis=0).reshape(-1)-np.concatenate(all_preds, axis=0).reshape(-1)))\n",
    "\n",
    "        print(\"R2_score: \", valR2) \n",
    "        print(\"Spearmans rho: {}, p_value: {}\".format(rho, p_value))\n",
    "        print('Pearson\\'r: {}, p_value: {}'.format(r_pearson,p_value_pearson))         \n",
    "        print('L2 loss:{}'.format(valL2Loss))\n",
    "\n",
    "        history[(epoch, \"prediction\")] = np.concatenate(all_preds, axis=0).reshape(-1)\n",
    "        history[(epoch, \"ground_truth\")] = np.concatenate(all_labels, axis=0).reshape(-1)\n",
    "        history[(epoch, \"val_loss\")] = valL2Loss\n",
    "        history[(epoch, \"val_r2\")] = valR2\n",
    "        history[(epoch, \"val_spearman\")] = (rho, p_value)\n",
    "        history[(epoch, \"val_pearson\")] = (r_pearson,p_value_pearson)\n",
    "    return history              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model\n",
      "Train on: 2015-17_ghana, Test on : 2009-11_nigeria\n",
      "Data Loaded\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "densenet121 (Model)             (None, 1000)         7037504     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 3010)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          512512      densenet121[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 512)          1541632     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          131328      dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          131328      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           dense_10[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 512)          262656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 256)          131328      dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           8224        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            33          dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 9,756,545\n",
      "Trainable params: 9,672,897\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Starting epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2195\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2196\u001b[0;31m         \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2197\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'densenet121_1/conv4_block14_0_bn/cond/Switch_1' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2199\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2201\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'densenet121_1/conv4_block14_0_bn/cond/Switch_1' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a47263b4ef7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'test_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfrecord_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtfrecord_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Doc2VecModel_Nightlight-new1.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-172628e1dbfb>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(tfrecord_train, tfrecord_test)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mmodel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtrainMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    508\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    510\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    511\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m     \"\"\"\n\u001b[0;32m-> 2757\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m--> 596\u001b[0;31m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 779\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    780\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    396\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 779\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    780\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_grad.py\u001b[0m in \u001b[0;36m_SwitchGrad\u001b[0;34m(op, *grad)\u001b[0m\n\u001b[1;32m     82\u001b[0m             [grad[op_ctxt.branch]] * 2, name=\"cond_resource_grad\")[0], None\n\u001b[1;32m     83\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cond_grad\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mfalse_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(inputs, name)\u001b[0m\n\u001b[1;32m    444\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one of the merge inputs is None: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Merge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     inputs = [\n\u001b[1;32m    448\u001b[0m         \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_convert_to_tensor_or_indexed_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5769\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5770\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5771\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5398\u001b[0m   \"\"\"\n\u001b[0;32m-> 5399\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5400\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5323\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5324\u001b[0m   \"\"\"\n\u001b[0;32m-> 5325\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5327\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhas_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4996\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4997\u001b[0m     \u001b[0;34m\"\"\"Override that returns a global default if the stack is empty.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4998\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DefaultGraphStack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4999\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5000\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GetGlobalDefaultGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4809\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4810\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4812\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = {}\n",
    "    result_dir = '/atlas/u/esheehan/GUF_dataset/output/'\n",
    "    tfrecord_dir = '/atlas/u/chenlin/wikipedia_images/Poverty_prediction/Processed_data/'\n",
    "    files = []\n",
    "#    with open(result_dir+'Doc2VecModel_Nightlight-new1.txt', 'rb') as f:\n",
    "#        results = pickle.load(f)\n",
    "    \n",
    "    #for tf_file in os.listdir(tfrecord_dir):\n",
    "    #    files.append(tf_file)\n",
    "#    files = ['2009-11_nigeria', '2012-14_ghana_','2009-11_malawi', '2009-11_uganda','2009-11_tanzania'] #,'2012-14_uganda', '2015-17_ghana', '2015-17_nigeria','2015-17_tanzania']\n",
    "\n",
    "    files = ['2015-17_ghana', '2009-11_nigeria']\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        for j in range(i+1,len(files),1):\n",
    "            tfrecord_train = tfrecord_dir + files[i]+'/'\n",
    "            tfrecord_test = tfrecord_dir + files[j]+'/'\n",
    "            print(\"Running model\\nTrain on: {}, Test on : {}\".format(files[i],files[j]))\n",
    "            file_name = result_dir + 'train_'+files[i]+'_' +'test_'+files[j]+'.txt'\n",
    "            if file_name not in results.keys():  \n",
    "                results[file_name] = run_model(tfrecord_train,tfrecord_test)\n",
    "  \n",
    "                with open(result_dir+'Doc2VecModel_Nightlight-new1.txt','wb') as f:\n",
    "                    pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            tfrecord_train = tfrecord_dir + files[j]+'/'\n",
    "            tfrecord_test = tfrecord_dir + files[i]+'/'\n",
    "            print(\"Running model\\nTrain on: {}, Test on : {}\".format(files[j],files[i]))\n",
    "            file_name = result_dir + 'train_'+files[j]+'_' +'test_'+files[i]+'.txt'\n",
    "            if file_name not in results.keys():\n",
    "                results[file_name] = run_model(tfrecord_train,tfrecord_test)\n",
    "            \n",
    "                with open(result_dir+'Doc2VecModel_Nightlight-new1.txt','wb') as f:\n",
    "                    pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    with open(result_dir+'Doc2VecModel_Nightlight-new1.txt','wb') as f:\n",
    "        pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
