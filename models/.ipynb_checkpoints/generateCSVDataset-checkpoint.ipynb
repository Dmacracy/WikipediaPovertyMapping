{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "saveRoot = \"/atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/\"\n",
    "dataRootPath = \"/atlas/u/chenlin/wikipedia_images/Poverty_prediction/\"\n",
    "toConvert = [\n",
    "#             'lx_median_2009-11_angola_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_burkina_faso_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_cameroon_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_ethiopia_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_lesotho_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_malawi_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_mozambique_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_nigeria_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_rwanda_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_senegal_dhslocs_ee_export.tfrecord.gz', \n",
    "#              'lx_median_2009-11_tanzania_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2009-11_uganda_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2009-11_zimbabwe_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_benin_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_burkina_faso_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_cote_d_ivoire_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_drc_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_ghana_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_guinea_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_kenya_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_lesotho_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_malawi_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_mali_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_nigeria_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_rwanda_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_senegal_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_sierra_leone_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_togo_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_uganda_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2012-14_zambia_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2015-17_angola_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2015-17_ethiopia_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2015-17_ghana_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2015-17_kenya_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2015-17_malawi_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2015-17_mali_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2015-17_nigeria_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2015-17_tanzania_dhslocs_ee_export.tfrecord.gz', \n",
    "             'lx_median_2015-17_zimbabwe_dhslocs_ee_export.tfrecord.gz'\n",
    "            ]\n",
    "\n",
    "options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "iterator = tf.python_io.tf_record_iterator(TFRecords_file, options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and types:\n",
      "{'ASP': 'float_list',\n",
      " 'BLUE': 'float_list',\n",
      " 'ELEV': 'float_list',\n",
      " 'GREEN': 'float_list',\n",
      " 'LAT': 'float_list',\n",
      " 'LON': 'float_list',\n",
      " 'NIGHTLIGHTS': 'float_list',\n",
      " 'NIR': 'float_list',\n",
      " 'RED': 'float_list',\n",
      " 'SLO': 'float_list',\n",
      " 'SWIR1': 'float_list',\n",
      " 'SWIR2': 'float_list',\n",
      " 'TEMP1': 'float_list',\n",
      " 'cluster_index': 'float_list',\n",
      " 'country': 'bytes_list',\n",
      " 'households': 'float_list',\n",
      " 'indx': 'float_list',\n",
      " 'lon': 'float_list',\n",
      " 'system:index': 'bytes_list',\n",
      " 'urban_rural': 'float_list',\n",
      " 'wealth': 'float_list',\n",
      " 'wealthpooled': 'float_list',\n",
      " 'wealthpooled5country': 'float_list',\n",
      " 'year': 'float_list'}\n"
     ]
    }
   ],
   "source": [
    "# get the first Example stored in the TFRecords file\n",
    "record_str = next(iterator)\n",
    "\n",
    "# parse the binary string\n",
    "ex = tf.train.Example.FromString(record_str)  # parse into an actual Example message\n",
    "features = ex.features  # get the Features message within the Example\n",
    "feature_map = features.feature  # get the mapping from feature name strings to Feature\n",
    "\n",
    "# use the WhichOneof() method on messages with `oneof` fields to\n",
    "# determine the type of the field\n",
    "feature_types = {}\n",
    "for name in feature_map.keys():\n",
    "    feature_types[name] = feature_map[name].WhichOneof('kind')\n",
    "\n",
    "print('Features and types:')\n",
    "pprint(feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCSV(TFRecords_file, saveFile):\n",
    "    print(\"Evaluating file: \", TFRecords_file)\n",
    "    options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "    iterator = tf.python_io.tf_record_iterator(TFRecords_file, options=options)\n",
    "\n",
    "    reqBands = ['LAT', 'LON', 'wealthpooled']\n",
    "\n",
    "    result = [] # (lat,lon), wealthpooled \n",
    "\n",
    "    for record_str in iterator:\n",
    "        ex = tf.train.Example.FromString(record_str)  # parse into an actual Example message\n",
    "        feature_map = ex.features.feature  # get the mapping from feature name strings to Feature\n",
    "\n",
    "        curLat = np.mean(feature_map['LAT'].float_list.value)\n",
    "        curLon = np.mean(feature_map['LON'].float_list.value)\n",
    "        curWealth = feature_map['wealthpooled'].float_list.value[0]\n",
    "\n",
    "        result.append(((curLat, curLon), curWealth))\n",
    "\n",
    "    print(len(result))\n",
    "    print(result[0])\n",
    "     \n",
    "    print(\"Saving file to \", saveFile)\n",
    "    np.save(saveFile, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_angola_dhslocs_ee_export.tfrecord.gz\n",
      "230\n",
      "((-11.914987152697993, 22.876721602795172), -1.019360899925232)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_angola_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_burkina_faso_dhslocs_ee_export.tfrecord.gz\n",
      "541\n",
      "((14.325220777474197, -1.4667242802825629), -0.8980481028556824)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_burkina_faso_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_cameroon_dhslocs_ee_export.tfrecord.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sailhome/esheehan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/sailhome/esheehan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n",
      "((6.358969385483686, 10.372711836122999), -0.9597873687744141)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_cameroon_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_ethiopia_dhslocs_ee_export.tfrecord.gz\n",
      "571\n",
      "((14.535319586361156, 40.14728209551643), -1.0181974172592163)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_ethiopia_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_lesotho_dhslocs_ee_export.tfrecord.gz\n",
      "395\n",
      "((-30.46974178389007, 27.94348929910099), -0.8784027695655823)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_lesotho_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_malawi_dhslocs_ee_export.tfrecord.gz\n",
      "827\n",
      "((-17.006183856141334, 35.14222866881128), -0.8595342636108398)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_malawi_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_mozambique_dhslocs_ee_export.tfrecord.gz\n",
      "879\n",
      "((-10.585244552761901, 40.52053209192613), -0.7069963812828064)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_mozambique_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_nigeria_dhslocs_ee_export.tfrecord.gz\n",
      "239\n",
      "((7.917094047396791, 3.2941670623480106), -0.5662975311279297)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_nigeria_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_rwanda_dhslocs_ee_export.tfrecord.gz\n",
      "492\n",
      "((-2.658014249801636, 28.910435874789368), -0.5214694142341614)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_rwanda_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_senegal_dhslocs_ee_export.tfrecord.gz\n",
      "385\n",
      "((16.123031376857384, -13.736004264681947), -0.0519392155110836)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_senegal_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_tanzania_dhslocs_ee_export.tfrecord.gz\n",
      "1031\n",
      "((-1.3601460704616473, 34.601083538579005), -0.5729790925979614)\n",
      "Saving file to  /atlas/u/esheehan/wikipedia_project/dataset/image_dataset/CS325B/lx_median_2009-11_tanzania_dhslocs_ee_export.tfrecord.gz.npy\n",
      "Evaluating file:  /atlas/u/chenlin/wikipedia_images/Poverty_prediction/lx_median_2009-11_uganda_dhslocs_ee_export.tfrecord\n"
     ]
    },
    {
     "ename": "DataLossError",
     "evalue": "inflate() failed with error -3: incorrect header check",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f3e2be8bd750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoConvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmakeCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataRootPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveRoot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-110eb0140f1c>\u001b[0m in \u001b[0;36mmakeCSV\u001b[0;34m(TFRecords_file, saveFile)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (lat,lon), wealthpooled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrecord_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_str\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# parse into an actual Example message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfeature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m  \u001b[0;31m# get the mapping from feature name strings to Feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36mtf_record_iterator\u001b[0;34m(path, options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mGetNext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetNext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyRecordReader_GetNext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: inflate() failed with error -3: incorrect header check"
     ]
    }
   ],
   "source": [
    "for file in toConvert:\n",
    "    makeCSV(dataRootPath + file, saveRoot + file + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
